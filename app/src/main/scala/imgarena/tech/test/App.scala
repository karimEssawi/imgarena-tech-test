/*
 * This Scala source file was generated by the Gradle 'init' task.
 */
package imgarena.tech.test

import org.apache.spark.sql.SparkSession
import org.apache.spark.sql.functions._


object App {
  def main(args: Array[String]): Unit = {
    val sparkSession = SparkSession.builder().config("spark.master", "local[*]").getOrCreate()
    sparkSession.sparkContext.setLogLevel("WARN")

    import sparkSession.implicits._
    val dataIO = new DataIO(sparkSession)
    val transformer = new Transformer(sparkSession)

    val sourceDf = dataIO.readCSV(this.getClass.getResource("/keystrokes-for-tech-test.csv").getPath)

    val jsonSchema = dataIO.inferJsonSchema(sourceDf, schemaIndex = 3)

//    pointScoredJsonSchema.printTreeString()
//      sparkSession.read.json(sourceDf.map(r => r.getString(3))).schema

    val dfWithSchema = sourceDf.withColumn("eventPayload", from_json($"match_element", jsonSchema)).persist()

    println("============== Flattening and enriching source dataframe ==================")
    val flattenedDf = transformer.flatten(dfWithSchema)
//    flattenedDf.show(false)

    println("============== Filling missing overall set scores for PointScored events ==================")
    val overallSetScoreDf = transformer.calcOverallSetScore(dfWithSchema)
    overallSetScoreDf.printSchema()
    overallSetScoreDf.show(false)
  }

  def greeting(): String = "Hello, world!"
}
