/*
 * This Scala source file was generated by the Gradle 'init' task.
 */
package imgarena.tech.test

import org.apache.spark.ml.feature.OneHotEncoder
import org.apache.spark.ml.linalg.DenseMatrix
import org.apache.spark.mllib.linalg.distributed.{CoordinateMatrix, IndexedRow, IndexedRowMatrix, MatrixEntry, RowMatrix}
import org.apache.spark.sql.{Row, SparkSession}
import org.apache.spark.sql.functions._
import org.apache.spark.mllib.linalg.{Matrices, Matrix, Vectors}
import org.apache.spark.sql.expressions.Window
import org.apache.spark.sql.types.ArrayType

import DataFrameUtils._


object App {
  def main(args: Array[String]): Unit = {
//    println(greeting())
    val sparkSession = SparkSession.builder().config("spark.master", "local[*]").getOrCreate()
    sparkSession.sparkContext.setLogLevel("WARN")

    import sparkSession.implicits._

    val df = sparkSession.read.option("header", true).option("mergeSchema", true).csv(this.getClass.getResource("/keystrokes-for-tech-test.csv").getPath)

    val json_schema = sparkSession.read.json(df.map(r => r.getString(3))).schema
//    json_schema.printTreeString()

//    val dfx = sparkSession.createDataFrame(Seq(
//      (0.0, 1.0),
//      (1.0, 0.0),
//      (2.0, 1.0),
//      (0.0, 2.0),
//      (0.0, 1.0),
//      (2.0, 0.0)
//    )).toDF("categoryIndex1", "categoryIndex2")
//
//    val encoder = new OneHotEncoder()
//      .setInputCols(Array("categoryIndex1", "categoryIndex2"))
//      .setOutputCols(Array("categoryVec1", "categoryVec2"))
//    val model = encoder.fit(dfx)
//
//    val encoded = model.transform(dfx)
//    encoded.printSchema()
//    encoded.show(false)

    val dfWithSchema = df.withColumn("eventPayload", from_json($"match_element", json_schema))

    val window = Window.partitionBy("match_id").orderBy("message_id")

    dfWithSchema
      .withColumn("pre_serve_state", lag("eventPayload", 1).over(window))
      .withColumn("post_serve_state", lead("eventPayload", 1).over(window))
      .withColumn("serveId", row_number().over(window))
      .withColumn("isPointStarted", $"eventPayload.eventElementType" === "PointStarted")
      .filter($"isPointStarted" === true)
      .filter($"match_id".isin(Seq("29304", "30941"):_*))
      .withColumn("state_before_serve",
        struct(
          $"eventPayload.server.team" as "server",
          when($"pre_serve_state.eventElementType" === "PhysioCalled", 1).otherwise(0) as "physio",
        )
      )
      .withColumn("serve_outcome",
        struct(
          when($"post_serve_state.eventElementType" === "PointLet", 1).otherwise(0) as "let",
          when($"post_serve_state.eventElementType" === "PointFault", 1).otherwise(0) as "fault",
          when($"post_serve_state.eventElementType" === "PointScored" && $"post_serve_state.details.scoredBy" === "TeamA", 1).otherwise(0) as "Team A scored",
          when($"post_serve_state.eventElementType" === "PointScored" && $"post_serve_state.details.scoredBy" === "TeamB", 1).otherwise(0) as "Team B scored",
        )
      )
      .withColumn("serveAttempt", when($"pre_serve_state.eventElementType" === "PointFault", "second").otherwise("first") )
      .select(

        $"match_id",
        $"state_before_serve",
        $"serveAttempt",
        $"serveId",
        $"serve_outcome",
//        $"eventPayload.server" as "server",
//        $"eventPayload",
        $"pre_serve_state.eventElementType" as "pre_serve_event",
        $"post_serve_state.eventElementType" as "post_serve_event",
        $"eventPayload",
      )
//      .groupBy("match_id", "isPointStarted")
//      .sort("match_id")
//      .groupBy("match_id")
//      .pivot($"pre_serve_state", Seq("PointFault"))
//      .agg(lit(1))

//      .pivot($"eventPayload.eventElementType")
//      .agg(collect_list($"eventPayload"))
//      .agg(lit(1))
//      .printSchema()
//      .show(1000,false)

//    dfWithSchema
////      .printSchema()
//      .map(r => {
//        val eventPayload = r.getStruct(4)
//        val str = eventPayload.getAs[String]("eventElementType")
//        if(str.equals("PointScored")) {
//          eventPayload.PointScored
//        }
//        else {
//          r
//        }
//      })

    val dfWithSchema2 = dfWithSchema
      .filter($"eventPayload.eventElementType" === "PointScored")
      .filter(size($"eventPayload.score.previousSetsScore") > 0)
      .select($"eventPayload.*")
      .as[Eventpayload]
//      .show()
//      .printSchema()
      .withColumn("overallSetScore",
        transform($"score.previousSetsScore", c => {
          val delta = c("gamesA") - c("gamesB")
          struct(
//            delta as "delta",
//            delta > 0 as "setA",
//            delta > 0 as "setA",
            lit(1) as "setA",
            lit(0) as "setB",
//            when(delta > (0), 1).otherwise(1) as "setA",
//            when(delta < 0L, 0).otherwise(1) as "setB"
          )

        })
      )
      .withColumn("overallSetScore",
        aggregate($"overallSetScore", struct(lit(0) as "setA",lit(0) as "setB"), (acc, v) => {
          struct(
//            acc + v
//            acc("setB") + v("setB") as "setsB",
            acc("setA") + v("setA") as "setsA",
            acc("setB") + v("setB") as "setsB",
          )
        })
      )
      .dropNestedColumn("score.overallSetScore")
      .withColumn("score", struct($"score.*", $"overallSetScore"))
      .drop("overallSetScore")

//      .show()
//        struct(
////          c
////        )
//      )
//    dfWithSchema2.printSchema()
//dfWithSchema2.show(false)
//    case class SetScore(gamesA: Long, gamesB: Long)

    //    println(SchemaToCaseClass.schema2Cc(dfWithSchema2.schema, "Mu"))
dfWithSchema2.show(100,false)
    dfWithSchema2.printSchema()

//    dfWithSchema.select($"eventPayload").show(100,false)

//    val schema = df.select($"match_element")
//    schema.printTreeString()
//    df.withColumn("eventType", $"match_element").printSchema()
  }

  def greeting(): String = "Hello, world!"
}
